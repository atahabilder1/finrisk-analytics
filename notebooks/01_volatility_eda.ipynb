{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility Exploratory Data Analysis\n",
    "**FinRisk Analytics - Project 2**\n\n",
    "Explore volatility patterns across asset classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('..')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport yaml\n\nfrom src.data.fetch_data import load_data\nfrom src.data.preprocess import prepare_returns, align_returns, calculate_realized_volatility, calculate_summary_statistics\nfrom src.utils.plotting import plot_returns, plot_volatility, plot_distribution, plot_qq, ensure_plot_dir\n\n# Set display options\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 100)\n\n# Load config\nwith open('../configs/config.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\nprint('‚úÖ Ready to analyze volatility!')"
  },
  {
   "cell_type": "code",
   "source": "## Volatility Clustering\n# Analyze volatility persistence\nprint(\"üîç Volatility Clustering Analysis\")\nprint(\"=\" * 60)\n\nfor ticker in returns_df.columns:\n    returns = returns_df[ticker]\n    squared_returns = returns ** 2\n    \n    # Autocorrelation of squared returns (measure of volatility clustering)\n    from pandas.plotting import autocorrelation_plot\n    \n    fig, ax = plt.subplots(figsize=(12, 6))\n    autocorrelation_plot(squared_returns.dropna(), ax=ax)\n    ax.set_title(f'{ticker} - Autocorrelation of Squared Returns\\n(Evidence of Volatility Clustering)')\n    ax.set_xlabel('Lag')\n    ax.set_ylabel('Autocorrelation')\n    plt.savefig(f'../results/plots/{ticker}_vol_clustering.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\nprint(\"\\n‚úÖ Volatility EDA Complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## Realized Volatility\n# Calculate and plot realized volatility\nvolatilities = {}\n\nfor ticker in returns_df.columns:\n    vol = calculate_realized_volatility(returns_df[ticker], window=20)\n    volatilities[ticker] = vol\n    \n    fig, ax = plot_volatility(vol,\n                              title=f'{ticker} Realized Volatility (20-day)',\n                              save_path=f'../results/plots/{ticker}_realized_vol.png')\n    plt.show()\n\n# Combine volatilities\nvol_df = pd.DataFrame(volatilities)\nprint(\"\\nüìà Average Annualized Volatility:\")\nprint(vol_df.mean().sort_values(ascending=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## Normality Check: Q-Q Plots\n# Test for normality\nfor ticker in returns_df.columns:\n    fig, ax = plot_qq(returns_df[ticker],\n                     title=f'{ticker} Q-Q Plot',\n                     save_path=f'../results/plots/{ticker}_qq.png')\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## Return Distribution Analysis\n# Check distribution characteristics\nfor ticker in returns_df.columns:\n    fig, ax = plot_distribution(returns_df[ticker],\n                                title=f'{ticker} Return Distribution',\n                                save_path=f'../results/plots/{ticker}_distribution.png')\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## Returns Visualization\n# Plot returns for each asset\nensure_plot_dir('../results/plots')\n\nfor ticker in returns_df.columns:\n    fig, ax = plot_returns(returns_df[ticker], \n                          title=f'{ticker} Daily Returns',\n                          save_path=f'../results/plots/{ticker}_returns.png')\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## Summary Statistics\n# Calculate summary statistics for each asset\nsummary_stats = {}\n\nfor col in returns_df.columns:\n    stats = calculate_summary_statistics(returns_df[col])\n    summary_stats[col] = stats\n\nstats_df = pd.DataFrame(summary_stats).T\nprint(\"\\nüìä Summary Statistics:\")\nstats_df",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load data for case studies\ncase_studies = config['assets']['case_studies']\nprice_data = {}\n\nfor ticker in case_studies:\n    df = load_data(ticker, data_dir='../data/raw')\n    if df is not None:\n        price_data[ticker] = df\n        print(f\"Loaded {ticker}: {df.shape[0]} rows\")\n\n# Calculate returns\nreturns_dict = prepare_returns(price_data)\nreturns_df = align_returns(returns_dict)\n\nprint(f\"\\nReturns DataFrame shape: {returns_df.shape}\")\nprint(f\"Date range: {returns_df.index[0]} to {returns_df.index[-1]}\")\nreturns_df.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}